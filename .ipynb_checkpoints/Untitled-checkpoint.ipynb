{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6af6a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3de2c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data2.json' # path of the file which has the processed data stored in JSON format\n",
    "\n",
    "def load_data(data_path):\n",
    "    '''\n",
    "    function to load data from the JSON file\n",
    "    param: data_path -> string -> the path of the JSON file which will be used to load data\n",
    "    return: X -> ndarray -> the extracted input features from the loaded file\n",
    "            Y -> ndarray -> the expected output for the corresponding inputs in X\n",
    "    '''\n",
    "    \n",
    "    with open(data_path, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    \n",
    "    # converting list to ndarrays\n",
    "    X = np.array(data['mfcc'])\n",
    "    Y = np.array(data['labels'])\n",
    "    print('Data Loaded Successfully!')\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X, Y = load_data(DATA_PATH) # loading data to X and Y\n",
    "\n",
    "def plot_history(history):\n",
    "    # function to plot the history of the training of the model\n",
    "    \n",
    "    fig, axs = plt.subplots(2)\n",
    "    \n",
    "    # plotting accuracy history of training and validation datasets\n",
    "    axs[0].plot(history.history[\"accuracy\"], label = 'train-accuracy')\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label = 'validation-accuracy')\n",
    "    axs[0].set_ylabel('accuracy')\n",
    "    axs[0].set_xlabel('epochs')\n",
    "    axs[0].legend(loc = 'lower right')\n",
    "    axs[0].set_title('Accuracy Evaluation')\n",
    "    \n",
    "    # plotting error history of training and validation datasets\n",
    "    axs[1].plot(history.history[\"loss\"], label = 'training-loss')\n",
    "    axs[1].plot(history.history[\"val_loss\"], label = 'validation-loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].legend('upper right')\n",
    "    axs[1].set_title('Loss Evaluation')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def prepare_dataset(validation_size, test_size):\n",
    "    # function to split the dataset into traning, validation and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_size)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = validation_size)\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_val = X_val[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    return X_train, X_val, X_test, Y_train, Y_val, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4477b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5991, 130, 40, 1) (5991,)\n",
      "(130, 40, 1)\n",
      "(None, 31, 9, 60)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_20\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [15, 4, 60], output_shape = [31, 540]\n\nCall arguments received by layer \"reshape_20\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 15, 4, 60), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 71>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_shape)\n\u001b[1;32m---> 76\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer,\n\u001b[0;32m     81\u001b[0m              loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     82\u001b[0m              metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# reshaping the dimensions to shift from cnn to rnn\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     reshape \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReshape(target_shape \u001b[38;5;241m=\u001b[39m (output_shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mint\u001b[39m(output_shape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m output_shape[\u001b[38;5;241m3\u001b[39m])))\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(reshape\u001b[38;5;241m.\u001b[39moutput_shape)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#     units_in_rnn = 30 # the number of units in the first rnn layer\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#     reshape = keras.layers.Dense(units_in_rnn, activation = 'relu')\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#     model.add(reshape)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\reshaping\\reshape.py:111\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[1;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[0;32m    109\u001b[0m   output_shape[unknown] \u001b[38;5;241m=\u001b[39m original \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m known\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original \u001b[38;5;241m!=\u001b[39m known:\n\u001b[1;32m--> 111\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_20\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [15, 4, 60], output_shape = [31, 540]\n\nCall arguments received by layer \"reshape_20\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 15, 4, 60), dtype=float32)"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape):\n",
    "    # building a RNN-LSTM model\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # adding Convolutional layers\n",
    "    cnn = keras.layers.Conv2D(30, (3, 3), activation = 'relu', input_shape = input_shape)\n",
    "    model.add(cnn)\n",
    "    \n",
    "    cnn = keras.layers.MaxPooling2D((2, 2), padding = 'same')\n",
    "    model.add(cnn)\n",
    "    \n",
    "    cnn = keras.layers.Conv2D(60, (3, 3), activation = 'relu')\n",
    "    model.add(cnn)\n",
    "    \n",
    "    cnn = keras.layers.MaxPooling2D((3, 3), strides = (2, 2), padding = 'same')\n",
    "    model.add(cnn)\n",
    "    \n",
    "    output_shape = cnn.output_shape\n",
    "    print(output_shape)\n",
    "#     print(model.layers[-1].output_shape)\n",
    "    \n",
    "    cnn = keras.layers.Conv2D(60, (3, 3), activation = 'relu')\n",
    "    model.add(cnn)\n",
    "    \n",
    "    cnn = keras.layers.MaxPooling2D((4, 4), strides = (2, 2), padding = 'same')\n",
    "    model.add(cnn)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # reshaping the dimensions to shift from cnn to rnn\n",
    "    reshape = keras.layers.Reshape(target_shape = (output_shape[1], int(output_shape[2] * output_shape[3])))\n",
    "    model.add(reshape)\n",
    "    print(reshape.output_shape)\n",
    "#     units_in_rnn = 30 # the number of units in the first rnn layer\n",
    "#     reshape = keras.layers.Dense(units_in_rnn, activation = 'relu')\n",
    "#     model.add(reshape)\n",
    "    \n",
    "    output_shape = reshape.output_shape\n",
    "    print(output_shape)\n",
    "    \n",
    "    rnn = keras.layers.GRU(30, return_sequences = True)\n",
    "    model.add(rnn)\n",
    "    \n",
    "    rnn = keras.layers.GRU(30)\n",
    "    model.add(rnn)\n",
    "    \n",
    "    output_shape = rnn.output_shape\n",
    "    print(output_shape)\n",
    "    \n",
    "    last = keras.layers.Dense(10, activation = 'softmax')\n",
    "    model.add(last)\n",
    "    \n",
    "    print(last.output_shape)\n",
    "#     model.add(keras.layers.Conv2D(30, (3, 3), activation = 'relu', input_shape = input_shape))\n",
    "#     model.add(keras.layers.MaxPooling2D((2, 2), strides = (2, 2), padding = 'same')) # pooling layer\n",
    "#     model.add(keras.layers.Conv2D(60, (3, 3), activation = 'relu'))\n",
    "#     model.add(keras.layers.MaxPooling2D((3, 3), strides = (2, 2), padding = 'same')) # pooling layer\n",
    "     # pooling layer\n",
    "#     model.add(keras.layers.Conv2D(60, (3, 3), activation = 'relu'))\n",
    "#     model.add(keras.layers.MaxPooling2D((4, 4), strides = (2, 2), padding = 'same')) # pooling layer\n",
    "    \n",
    "    # adding LSTM layers\n",
    "#     model.add(keras.layers.LSTM(64, input_shape = input_shape, return_sequences = True))\n",
    "#     model.add(keras.layers.LSTM(64))\n",
    "    \n",
    "#     # dense neural network layer\n",
    "#     model.add(keras.layers.Dense(64, activation = 'relu'))\n",
    "#     model.add(keras.layers.Dropout(0.3))\n",
    "#     model.add(keras.layers.Dense(32, activation = 'relu'))\n",
    "#     model.add(keras.layers.Dropout(0.3))\n",
    "#     # final softmax layer \n",
    "#     model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "if(__name__ == '__main__'):\n",
    "    X_train, X_val, X_test, Y_train, Y_val, Y_test = prepare_dataset(0.25, 0.2)\n",
    "    print(X_train.shape, Y_train.shape)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "    print(input_shape)\n",
    "    model = build_model(input_shape)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "    \n",
    "    model.compile(optimizer = optimizer,\n",
    "                 loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), batch_size = 32, epochs = 50)\n",
    "    \n",
    "    plot_history(history)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test, Y_test, verbose = 2)\n",
    "    \n",
    "    print(f'Test Accuracy: {test_acc}')\n",
    "    \n",
    "    X_to_predict = X_test[300]\n",
    "    Y_to_predict = Y_test[300]\n",
    "    \n",
    "    predict(model, X_to_predict, Y_to_predict)\n",
    "    \n",
    "    print(X.shape, Y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
