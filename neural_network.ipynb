{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e40e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266b65cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data.json' # path of the file which has the processed data stored in JSON format\n",
    "\n",
    "def load_data(data_path):\n",
    "    '''\n",
    "    function to load data from the JSON file\n",
    "    param: data_path -> string -> the path of the JSON file which will be used to load data\n",
    "    return: X -> ndarray -> the extracted input features from the loaded file\n",
    "            Y -> ndarray -> the expected output for the corresponding inputs in X\n",
    "    '''\n",
    "    \n",
    "    with open(data_path, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    \n",
    "    # converting list to ndarrays\n",
    "    X = np.array(data['mfcc'])\n",
    "    Y = np.array(data['labels'])\n",
    "    print('Data Loaded Successfully!')\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X, Y = load_data(DATA_PATH) # loading data to X and Y\n",
    "\n",
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(2)\n",
    "    \n",
    "    axs[0].plot(history.history[\"accuracy\"], label = 'train-accuracy')\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label = 'validation-accuracy')\n",
    "    axs[0].set_ylabel('accuracy')\n",
    "    axs[0].set_xlabel('epochs')\n",
    "    axs[0].legend(loc = 'lower right')\n",
    "    axs[0].set_title('Accuracy Evaluation')\n",
    "    \n",
    "    axs[1].plot(history.history[\"loss\"], label = 'training-loss')\n",
    "    axs[1].plot(history.history[\"val_loss\"], label = 'validation-loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].legend('upper right')\n",
    "    axs[1].set_title('Loss Evaluation')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_8 (Flatten)         (None, 1690)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 512)               865792    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 63)                16191     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 63)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                640       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,013,951\n",
      "Trainable params: 1,013,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 28.1724 - accuracy: 0.1609 - val_loss: 3.4916 - val_accuracy: 0.2634\n",
      "Epoch 2/50\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 7.7001 - accuracy: 0.1698 - val_loss: 3.4210 - val_accuracy: 0.1993\n",
      "Epoch 3/50\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 5.0229 - accuracy: 0.1628 - val_loss: 3.4679 - val_accuracy: 0.1475\n",
      "Epoch 4/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 4.1849 - accuracy: 0.1682 - val_loss: 3.4769 - val_accuracy: 0.1308\n",
      "Epoch 5/50\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 3.9145 - accuracy: 0.1544 - val_loss: 3.4692 - val_accuracy: 0.1252\n",
      "Epoch 6/50\n",
      "219/219 [==============================] - 4s 19ms/step - loss: 3.7364 - accuracy: 0.1611 - val_loss: 3.4517 - val_accuracy: 0.1385\n",
      "Epoch 7/50\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 3.6379 - accuracy: 0.1667 - val_loss: 3.4278 - val_accuracy: 0.1529\n",
      "Epoch 8/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 3.5324 - accuracy: 0.1798 - val_loss: 3.3933 - val_accuracy: 0.1762\n",
      "Epoch 9/50\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 3.4953 - accuracy: 0.1994 - val_loss: 3.3524 - val_accuracy: 0.2066\n",
      "Epoch 10/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 3.4239 - accuracy: 0.2129 - val_loss: 3.2955 - val_accuracy: 0.2333\n",
      "Epoch 11/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 3.4041 - accuracy: 0.2196 - val_loss: 3.2068 - val_accuracy: 0.2770\n",
      "Epoch 12/50\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 3.3516 - accuracy: 0.2365 - val_loss: 3.1748 - val_accuracy: 0.2924\n",
      "Epoch 13/50\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 3.3233 - accuracy: 0.2416 - val_loss: 3.1370 - val_accuracy: 0.3027\n",
      "Epoch 14/50\n",
      "219/219 [==============================] - 4s 19ms/step - loss: 3.2553 - accuracy: 0.2627 - val_loss: 3.0808 - val_accuracy: 0.3188\n",
      "Epoch 15/50\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 3.2537 - accuracy: 0.2662 - val_loss: 3.0232 - val_accuracy: 0.3354\n",
      "Epoch 16/50\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 3.2098 - accuracy: 0.2750 - val_loss: 3.0419 - val_accuracy: 0.3221\n",
      "Epoch 17/50\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 3.1488 - accuracy: 0.2765 - val_loss: 3.0324 - val_accuracy: 0.3204\n",
      "Epoch 18/50\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 3.1207 - accuracy: 0.2881 - val_loss: 2.9382 - val_accuracy: 0.3425\n",
      "Epoch 19/50\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 3.1237 - accuracy: 0.2804 - val_loss: 2.9351 - val_accuracy: 0.3455\n",
      "Epoch 20/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 3.0726 - accuracy: 0.2957 - val_loss: 2.8970 - val_accuracy: 0.3642\n",
      "Epoch 21/50\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 3.0427 - accuracy: 0.3040 - val_loss: 2.8451 - val_accuracy: 0.3528\n",
      "Epoch 22/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 3.0467 - accuracy: 0.2917 - val_loss: 2.8747 - val_accuracy: 0.3555\n",
      "Epoch 23/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 2.9916 - accuracy: 0.3102 - val_loss: 2.7936 - val_accuracy: 0.3655\n",
      "Epoch 24/50\n",
      "219/219 [==============================] - 4s 18ms/step - loss: 2.9839 - accuracy: 0.3076 - val_loss: 2.8533 - val_accuracy: 0.3391\n",
      "Epoch 25/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 2.9200 - accuracy: 0.3220 - val_loss: 2.8102 - val_accuracy: 0.3601\n",
      "Epoch 26/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 2.8943 - accuracy: 0.3246 - val_loss: 2.7630 - val_accuracy: 0.3658\n",
      "Epoch 27/50\n",
      "219/219 [==============================] - 4s 17ms/step - loss: 2.8530 - accuracy: 0.3278 - val_loss: 2.7219 - val_accuracy: 0.3725\n",
      "Epoch 28/50\n",
      "100/219 [============>.................] - ETA: 1s - loss: 2.8978 - accuracy: 0.3169"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # splitting the data to training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "    \n",
    "    # defining a Neural Network\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (X.shape[1], X.shape[2])),\n",
    "        keras.layers.Dense(512, activation = 'relu', kernel_regularizer = keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(63, activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "    \n",
    "    # compiling the model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                 loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, \n",
    "                        validation_data = (X_test, Y_test),\n",
    "                       batch_size = 32, epochs = 50)\n",
    "    \n",
    "    plot_history(history)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
